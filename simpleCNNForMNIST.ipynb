{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrialForGAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"ToTKZH_Dw1aM","colab_type":"code","outputId":"83c1b1e5-90cc-420c-81b3-190998abe97e","executionInfo":{"status":"ok","timestamp":1544032937895,"user_tz":360,"elapsed":43654,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"cell_type":"code","source":["!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "],"execution_count":20,"outputs":[{"output_type":"stream","text":["Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n","\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n","\u001b[K    100% |████████████████████████████████| 592.3MB 45.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n","Installing collected packages: torch\n","Successfully installed torch-0.3.0.post4\n"],"name":"stdout"}]},{"metadata":{"id":"ed4pSPOXxLzd","colab_type":"code","outputId":"103054a8-b6f4-43d9-eeb4-ec0254f0b30b","executionInfo":{"status":"ok","timestamp":1544032969469,"user_tz":360,"elapsed":4568,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"cell_type":"code","source":["!pip3 install torchvision"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Collecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n","Installing collected packages: pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"K-oFm8j6yqJD","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UNO4LRo1y_Oi","colab_type":"code","colab":{}},"cell_type":"code","source":["input_size    = 784   # The image size = 28 x 28 = 784\n","hidden_size   = 500   # The number of nodes at the hidden layer\n","num_classes   = 10    # The number of output classes. In this case, from 0 to 9\n","batch_size    = 100   # The size of input data took for one iteration\n","learning_rate = 1e-2  # The speed of convergence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3VKpeEjPzLyK","colab_type":"code","outputId":"d4b3d075-ac9c-4bc8-e93f-ae09ef3e4f9f","executionInfo":{"status":"ok","timestamp":1544032990658,"user_tz":360,"elapsed":10753,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["compose = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n","        ])\n","train_dataset = dsets.MNIST(root='./data',\n","                           train=True,\n","                           transform=compose,\n","                           download=True)\n","\n","test_dataset = dsets.MNIST(root='./data',\n","                           train=False,\n","                           transform=compose,\n","                           download=True)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Processing...\n","Done!\n"],"name":"stdout"}]},{"metadata":{"id":"Kzdo2FopIOdr","colab_type":"code","colab":{}},"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F8NqL2FDIa2z","colab_type":"code","colab":{}},"cell_type":"code","source":["def outputSize(in_size, kernel_size, stride, padding):\n","\n","  output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n","\n","  return(output)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wX67k8cEzWQi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ba48d528-75b3-42ff-97da-337c3410daaf","executionInfo":{"status":"ok","timestamp":1544033013260,"user_tz":360,"elapsed":222,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}}},"cell_type":"code","source":["outputSize(3,2,2,0)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"BYUpR74fzeUS","colab_type":"code","colab":{}},"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n","        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n","        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n","        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n","    \n","    def forward(self, x):                              # Forward pass: stacking each layer together\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xqI_atn2ztli","colab_type":"code","colab":{}},"cell_type":"code","source":["net = Net(input_size, hidden_size, num_classes)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Ec0FvhYIK-w","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"WJRJKhtHCjG1","colab_type":"text"},"cell_type":"markdown","source":["***SImple CNN Model***"]},{"metadata":{"id":"How-8r5BCiVE","colab_type":"code","colab":{}},"cell_type":"code","source":["class SimpleCNN(torch.nn.Module):\n","    \n","    #Our batch shape for input x is (3, 32, 32)\n","    \n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        \n","        #Input channels = 1, output channels = 128\n","        #Feauremap Input size = 28, output channels = 14\n","        self.conv1 = torch.nn.Conv2d(1, 128, kernel_size=3, stride=1, padding=1)\n","        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        #Input channels = 128, output channels = 256\n","        #Feauremap Input size = 14, output channels = 7\n","        self.conv2 = torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n","        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","         #Input channels = 256, output channels = 128\n","         #Feauremap Input size = 7, output channels = 3\n","        self.conv3 = torch.nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n","        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        #Input channels =128, output channels = 64\n","        #Feauremap Input size = 3, output channels = 1\n","        self.conv4 = torch.nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        #input features, 64 output features (see sizing flow below)\n","        self.fc1 = torch.nn.Linear(64, 128)\n","        \n","        #64 input features, 10 output features for our 10 defined classes\n","        self.fc2 = torch.nn.Linear(128, 10)\n","        \n","    def forward(self, x):\n","        \n","        #Computes the activation of the first convolution\n","        #Size changes from (3, 32, 32) to (18, 32, 32)\n","        x = F.relu(self.conv1(x))\n","        \n","        #Size changes from (18, 32, 32) to (18, 16, 16)\n","        x = self.pool(x)\n","        \n","        x = F.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        \n","        x = F.relu(self.conv3(x))\n","        x = self.pool3(x)\n","        \n","        x = F.relu(self.conv4(x))\n","        x = self.pool4(x)\n","        \n","        \n","        #Reshape data to input to the input layer of the neural net\n","        #Size changes from (18, 16, 16) to (1, 4608)\n","        #Recall that the -1 infers this dimension from the other given dimension\n","        x = x.view(-1, 64)\n","        \n","        #Computes the activation of the first fully connected layer\n","        #Size changes from (1, 4608) to (1, 64)\n","        x = F.relu(self.fc1(x))\n","        \n","        #Computes the second fully connected layer (activation applied later)\n","        #Size changes from (1, 64) to (1, 10)\n","        x = self.fc2(x)\n","        return(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ohpGRDTYDZge","colab_type":"code","colab":{}},"cell_type":"code","source":["sCNN = SimpleCNN()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-OnQic07zv7y","colab_type":"code","colab":{}},"cell_type":"code","source":["use_cuda = True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2TJu2OvDzyXq","colab_type":"code","colab":{}},"cell_type":"code","source":["if use_cuda and torch.cuda.is_available():\n","#     net.cuda()\n","    sCNN.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EfLvEXS8AMmu","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"85uTjFH9z0Jy","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(sCNN.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LHhksS8g0VBx","colab_type":"code","outputId":"d5e03726-d0f8-4955-8166-6db9d63afcfe","executionInfo":{"status":"ok","timestamp":1544033318056,"user_tz":360,"elapsed":205621,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"cell_type":"code","source":["num_epochs    = 10     # The number of times entire dataset is trained\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n","#         images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n","        images = Variable(images)\n","        labels = Variable(labels)\n","#         print(images.shape)\n","\n","        if use_cuda and torch.cuda.is_available():\n","            images = images.cuda()\n","            labels = labels.cuda()\n","        \n","        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n","        outputs = sCNN(images)                             # Forward pass: compute the output class given a image\n","#         print(outputs.shape)\n","        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n","        loss.backward()                                   # Backward pass: compute the weight\n","        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n","        \n","        if (i+1) % 600 == 0:                              # Logging\n","            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n","                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Epoch [1/10], Step [600/600], Loss: 0.3074\n","Epoch [2/10], Step [600/600], Loss: 0.3336\n","Epoch [3/10], Step [600/600], Loss: 0.2549\n","Epoch [4/10], Step [600/600], Loss: 0.2247\n","Epoch [5/10], Step [600/600], Loss: 0.0931\n","Epoch [6/10], Step [600/600], Loss: 0.1012\n","Epoch [7/10], Step [600/600], Loss: 0.0753\n","Epoch [8/10], Step [600/600], Loss: 0.1323\n","Epoch [9/10], Step [600/600], Loss: 0.0417\n","Epoch [10/10], Step [600/600], Loss: 0.0804\n"],"name":"stdout"}]},{"metadata":{"id":"DlD-Hu981Y11","colab_type":"text"},"cell_type":"markdown","source":["**Testing on the test data**"]},{"metadata":{"id":"jabXV34J1V-E","colab_type":"code","outputId":"9eb76c34-5f30-4922-d012-f18fd6a22aad","executionInfo":{"status":"ok","timestamp":1544033336505,"user_tz":360,"elapsed":2898,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["correct = 0\n","total = 0\n","for images, labels in test_loader:\n","    images = Variable(images)\n","    \n","    if use_cuda and torch.cuda.is_available():\n","        images = images.cuda()\n","        labels = labels.cuda()\n","    \n","    \n","    outputs = sCNN(images)\n","    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n","    total += labels.size(0)                    # Increment the total count\n","    correct += (predicted == labels).sum()     # Increment the correct count\n","    \n","print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10K test images: 96 %\n"],"name":"stdout"}]},{"metadata":{"id":"D-bgcwI01nfI","colab_type":"code","colab":{}},"cell_type":"code","source":["torch.save(sCNN.state_dict(), 'simpleCNN_model.pkl')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J66qrKbo3282","colab_type":"code","outputId":"a4aeed56-0a2a-429e-c700-014969c067bf","executionInfo":{"status":"ok","timestamp":1542583850912,"user_tz":360,"elapsed":206,"user":{"displayName":"Vinayak Daramwar","photoUrl":"","userId":"01774353816048275374"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"id":"jXNNKc8NKZaY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}